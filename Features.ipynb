{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['order_id', 'product_id', 'quantity', 'buy_unit'], dtype='object')\n",
      "Index(['order_id', 'lat', 'lng', 'promised_time', 'on_demand', 'shopper_id',\n",
      "       'store_branch_id', 'total_minutes'],\n",
      "      dtype='object')\n",
      "Index(['shopper_id', 'seniority', 'found_rate', 'picking_speed',\n",
      "       'accepted_rate', 'rating'],\n",
      "      dtype='object')\n",
      "Index(['store_branch_id', 'store_id', 'lat', 'lng'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'matiasalvo'\n",
    "\n",
    "import pandas as pd\n",
    "from geopy import distance\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "products= pd.read_csv(\"data/order_products.csv\")\n",
    "orders = pd.read_csv(\"data/orders.csv\")\n",
    "shoppers = pd.read_csv(\"data/shoppers.csv\")\n",
    "store = pd.read_csv(\"data/storebranch.csv\")\n",
    "\n",
    "print(products.columns)\n",
    "print(orders.columns)\n",
    "print(shoppers.columns)\n",
    "print(store.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shopper_id         0\n",
      "seniority          0\n",
      "found_rate       101\n",
      "picking_speed      0\n",
      "accepted_rate     27\n",
      "rating            84\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#There are null_values for some shoppers.  We will replace it with the average value of the column\n",
    "print((shoppers.isnull().sum(axis = 0)))\n",
    "shoppers = shoppers.fillna(shoppers.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We add dummy variables for each type of seniority\n",
    "unique_seniority = shoppers.seniority.unique()\n",
    "for (i,key) in enumerate(unique_seniority):\n",
    "    shoppers[\"seniority {}\".format(i)] = shoppers.apply(lambda row: 1 if row.seniority == key else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create the columns of units and kgs\n",
    "products[\"kg\"] = products.apply(lambda row: row.quantity if row.buy_unit == \"KG\" else 0, axis = 1)\n",
    "products[\"un\"] = products.apply(lambda row: row.quantity if row.buy_unit == \"un\" else 0, axis = 1)\n",
    "\n",
    "#For each order, we sum the units and kgs and we count the distinct products\n",
    "products_gb = products.groupby(\"order_id\").agg({\"product_id\":\"count\", \n",
    "                                                \"quantity\":\"sum\",\"kg\":\"sum\"}).reset_index().rename(columns={\"product_id\":\"distinct_products\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We join the datasets\n",
    "df = orders.set_index(\"shopper_id\").join(shoppers.set_index(\"shopper_id\")).reset_index()\n",
    "df = df.set_index(\"store_branch_id\").join(store.set_index(\"store_branch_id\"),lsuffix=\"_client\",rsuffix=\"_store\").reset_index()\n",
    "df = df.set_index(\"order_id\").join(products_gb.set_index(\"order_id\")).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                0\n",
       "store_branch_id         0\n",
       "shopper_id              0\n",
       "lat_client              0\n",
       "lng_client              0\n",
       "promised_time           0\n",
       "on_demand               0\n",
       "total_minutes        1995\n",
       "seniority               0\n",
       "found_rate              0\n",
       "picking_speed           0\n",
       "accepted_rate           0\n",
       "rating                  0\n",
       "seniority 0             0\n",
       "seniority 1             0\n",
       "seniority 2             0\n",
       "seniority 3             0\n",
       "store_id                0\n",
       "lat_store               0\n",
       "lng_store               0\n",
       "distinct_products       0\n",
       "quantity                0\n",
       "kg                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are 22 orders without products.  As it is only a few, we are just going to drop them\n",
    "df.isnull().sum(axis = 0)\n",
    "df.dropna(subset=['kg'], how='all', inplace=True)\n",
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the distance between shop and customer\n",
    "df[\"distance\"] = df.apply(lambda row: distance.geodesic((row.lat_client,row.lng_client),(row.lat_store,row.lng_store)).km, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a few variables that may be useful\n",
    "df[\"quantity_ratio\"] = df[\"quantity\"]/df[\"picking_speed\"]\n",
    "df[\"distinct_ratio\"] = df[\"distinct_products\"]/df[\"picking_speed\"]\n",
    "df[\"kg_ratio\"] = df[\"kg\"]/df[\"picking_speed\"]\n",
    "df[\"on_demand\"] = df.on_demand.map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We add dummy variable for store_branch_id and store_id\n",
    "dummies = pd.get_dummies(df[\"store_branch_id\"],prefix=\"store_branch\")\n",
    "# dummies2 = pd.get_dummies(df[\"store_id\"],prefix=\"store_\") #I tried these dummies and is worst for the models\n",
    "df = pd.concat([df,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We normalize the variables so gradient descent works faster and regularization terms penalize\n",
    "#each variable with the same weights\n",
    "def normalize(df,columns):\n",
    "    normalized = {x:{\"mean\":0, \"std\":0} for x in to_norm}\n",
    "    for key in columns:\n",
    "        mean = df[key].mean()\n",
    "        std = df[key].std()\n",
    "        normalized[key][\"mean\"] = mean\n",
    "        normalized[key][\"std\"] = std\n",
    "        df[key] = (df[key]-mean)/std\n",
    "    return df, normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(df,normalized):\n",
    "    for key,value in normalized.items():\n",
    "        if key != \"total_minutes\":\n",
    "            df[key] = df[key]*value[\"std\"] + value[\"mean\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define columns to normalize, so the linear regression works faster\n",
    "to_norm = [\"found_rate\", \"picking_speed\", \"accepted_rate\", \"rating\", \"distinct_products\",\n",
    "           \"quantity\", \"kg\", \"distance\",\"quantity_ratio\", \"distinct_ratio\", \"kg_ratio\"]\n",
    "# We normalize the variables\n",
    "df, normalized = normalize(df, to_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset the index and shuffle in case it was ordered (to get same distribution of train and test)\n",
    "df = df.sample(frac=1, random_state=30).reset_index(drop=True)\n",
    "#Dump the dataset \n",
    "df.to_pickle(\"data/regression_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split null and not null total_minutes entries, define training and test sets and drop columns we wont use\n",
    "not_nulls = df[df.total_minutes.notnull()].drop(columns=[\"order_id\",\"lat_client\",\"lng_client\",\"promised_time\",\n",
    "                            \"seniority\", \"store_id\",\"lat_store\",\"lng_store\",\"shopper_id\", \"store_branch_id\"]\n",
    "                                                ,axis=1).reset_index(drop=True)\n",
    "y = not_nulls.total_minutes\n",
    "x = not_nulls.drop(columns=[\"total_minutes\"])\n",
    "train_x, val_test_x, train_y, val_test_y = train_test_split(x,y,test_size = 0.3, shuffle=False)\n",
    "val_x, test_x, val_y, test_y = train_test_split(val_test_x,val_test_y,test_size = 0.5, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = df[df.total_minutes.isna()].drop(columns=[\"lat_client\",\"lng_client\",\"promised_time\",\n",
    "                            \"seniority\", \"store_id\",\"lat_store\",\"lng_store\",\"shopper_id\",\"store_branch_id\"],axis=1).reset_index(drop=True)\n",
    "y_nulls = nulls[[\"order_id\"]]\n",
    "x_nulls = nulls.drop(columns=[\"total_minutes\", \"order_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.to_pickle(\"data/train_x.pkl\")\n",
    "val_x.to_pickle(\"data/val_x.pkl\")\n",
    "test_x.to_pickle(\"data/test_x.pkl\")\n",
    "x_nulls.to_pickle(\"data/x_nulls.pkl\")\n",
    "\n",
    "train_y.to_pickle(\"data/train_y.pkl\")\n",
    "val_y.to_pickle(\"data/val_y.pkl\")\n",
    "test_y.to_pickle(\"data/test_y.pkl\")\n",
    "y_nulls.to_pickle(\"data/y_nulls.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
